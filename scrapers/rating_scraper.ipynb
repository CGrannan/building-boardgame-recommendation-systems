{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the indexes of the 2000 most popular games supplied by our preliminary cleaning notebook. We will scrape 2000 reviews from each of these games using the boardgamegeek api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import time\n",
    "import datetime\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>game_id</th>\n",
       "      <th>num_ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>822</td>\n",
       "      <td>98777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>98557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68448</td>\n",
       "      <td>82043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36218</td>\n",
       "      <td>76396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9209</td>\n",
       "      <td>69577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   game_id  num_ratings\n",
       "0      822        98777\n",
       "1       13        98557\n",
       "2    68448        82043\n",
       "3    36218        76396\n",
       "4     9209        69577"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_scrape = pd.read_csv('cleaned_data/high_review_count_games')\n",
    "to_scrape.columns = ['game_id', 'num_ratings']\n",
    "to_scrape.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each request we make will be for 100 reviews(maximum per page) for each of 100 games (we could do more, but we run into issues as our index numbers get bigger). We will write into a csv the game id, user_id, rating (out of 10), and comment if available for each rating. We will limit the length of our csvs to 100,000 items, so we will be looking for around 40 csv files to be created. We will use these files in another notebook to begin the process of creating our recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "Set Complete\n",
      "429\n",
      "17 4\n",
      "429\n",
      "18 15\n",
      "Set Complete\n",
      "429\n",
      "19 8\n",
      "Set Complete\n",
      "429\n",
      "21 4\n",
      "429\n",
      "22 15\n",
      "Set Complete\n",
      "429\n",
      "23 7\n",
      "429\n",
      "23 16\n",
      "Set Complete\n",
      "429\n",
      "25 13\n",
      "Set Complete\n",
      "429\n",
      "26 8\n",
      "429\n",
      "27 18\n",
      "Set Complete\n",
      "429\n",
      "29 15\n",
      "Set Complete\n",
      "429\n",
      "30 11\n",
      "Set Complete\n",
      "429\n",
      "32 5\n",
      "429\n",
      "33 16\n",
      "Set Complete\n",
      "429\n",
      "34 7\n",
      "429\n",
      "35 18\n",
      "Set Complete\n",
      "429\n",
      "36 11\n",
      "429\n",
      "36 20\n",
      "Set Complete\n",
      "429\n",
      "37 10\n",
      "Set Complete\n",
      "0:16:32.009875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "\n",
    "pages = range(1, 21)\n",
    "comment_counter = 1\n",
    "csv_counter = 1\n",
    "with open(f'scraped_ratings/ratings{csv_counter}.csv','w', newline='') as file:\n",
    "    while len(to_scrape) > 0:\n",
    "        this_batch = to_scrape[:100]\n",
    "        string_ids = ''\n",
    "        for game in this_batch.game_id:\n",
    "            string_ids += (str(game) + ',')\n",
    "        for page in pages:\n",
    "            response = requests.get(f'https://www.boardgamegeek.com/xmlapi2/thing?id={string_ids}&ratingcomments=1&pagesize=100&page={page}')\n",
    "            if response.status_code == 404:\n",
    "                print('404', page)\n",
    "                \n",
    "            elif response.status_code == 200:\n",
    "                    content = response.content\n",
    "                    soup = BeautifulSoup(content, \"xml\")\n",
    "                    items = soup.findAll('item')\n",
    "                    for item in items:\n",
    "                        game_id = item.get('id')\n",
    "                        comments = item.findAll('comment')\n",
    "                        for comment in comments:\n",
    "                            file.write(f\"{game_id}\\t{comment.get('username')}\\t{comment.get('rating')}\\t{comment.get('value')}\")\n",
    "                            file.write('\\n')\n",
    "                            comment_counter += 1\n",
    "                            if comment_counter > 100000:\n",
    "                                csv_counter += 1\n",
    "                                comment_counter = 1\n",
    "                                file = open(f'scraped_ratings/ratings{csv_counter}.csv','w', newline='')\n",
    "\n",
    "            else:\n",
    "                print(response.status_code)\n",
    "                print(csv_counter, page)\n",
    "                time.sleep(15)\n",
    "        \n",
    "            if comment_counter > 100000:\n",
    "                csv_counter += 1\n",
    "                comment_counter = 1\n",
    "                file = open(f'scraped_ratings/ratings{csv_counter}.csv','w', newline='')\n",
    "                                       \n",
    "        to_scrape.drop(this_batch.index, axis=0, inplace=True)\n",
    "\n",
    "        time.sleep(3)\n",
    "        print('Set Complete')\n",
    "end= datetime.datetime.now()\n",
    "print(end-start)\n",
    "len(to_scrape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
